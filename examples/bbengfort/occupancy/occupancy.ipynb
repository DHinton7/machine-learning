{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Occupancy Detection\n",
    "\n",
    "Create a classification model to determine if a room is occupied or unoccupied based on environmental data. \n",
    "\n",
    "In class demo on May 5, 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction import DictVectorizer \n",
    "from sklearn.base import BaseEstimator, TransformerMixin \n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split as tts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Load data in two ways: \"raw\" form as dictionaries to use with the `DictVectorizer` and as a Pandas DataFrame for data exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = os.path.join(\"data\", \"occupancy.csv\")\n",
    "DTFMT = '%Y-%m-%d %H:%M:%S'\n",
    "\n",
    "def load_raw(path=DATA):\n",
    "    with open(path, 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            # Pop target off of features dictionary \n",
    "            target = row.pop('occupancy')\n",
    "            \n",
    "            # Convert fields to floats\n",
    "            for field in ('temperature', 'relative humidity', 'C02', 'humidity', 'light'):\n",
    "                row[field] = float(row[field])\n",
    "            \n",
    "            # Parse datetime\n",
    "            row['datetime'] = datetime.strptime(row['datetime'], DTFMT)\n",
    "            \n",
    "            yield row, target\n",
    "            \n",
    "            \n",
    "def load_df(path=DATA):\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>relative humidity</th>\n",
       "      <th>light</th>\n",
       "      <th>C02</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20560.000000</td>\n",
       "      <td>20560.000000</td>\n",
       "      <td>20560.000000</td>\n",
       "      <td>20560.000000</td>\n",
       "      <td>20560.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20.906212</td>\n",
       "      <td>27.655925</td>\n",
       "      <td>130.756622</td>\n",
       "      <td>690.553276</td>\n",
       "      <td>0.004228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.055315</td>\n",
       "      <td>4.982154</td>\n",
       "      <td>210.430875</td>\n",
       "      <td>311.201281</td>\n",
       "      <td>0.000768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>16.745000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>412.750000</td>\n",
       "      <td>0.002674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.200000</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>460.000000</td>\n",
       "      <td>0.003719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20.700000</td>\n",
       "      <td>27.290000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>565.416667</td>\n",
       "      <td>0.004292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>21.525000</td>\n",
       "      <td>31.290000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>804.666667</td>\n",
       "      <td>0.004832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>24.408333</td>\n",
       "      <td>39.500000</td>\n",
       "      <td>1697.250000</td>\n",
       "      <td>2076.500000</td>\n",
       "      <td>0.006476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        temperature  relative humidity         light           C02  \\\n",
       "count  20560.000000       20560.000000  20560.000000  20560.000000   \n",
       "mean      20.906212          27.655925    130.756622    690.553276   \n",
       "std        1.055315           4.982154    210.430875    311.201281   \n",
       "min       19.000000          16.745000      0.000000    412.750000   \n",
       "25%       20.200000          24.500000      0.000000    460.000000   \n",
       "50%       20.700000          27.290000      0.000000    565.416667   \n",
       "75%       21.525000          31.290000    301.000000    804.666667   \n",
       "max       24.408333          39.500000   1697.250000   2076.500000   \n",
       "\n",
       "           humidity  \n",
       "count  20560.000000  \n",
       "mean       0.004228  \n",
       "std        0.000768  \n",
       "min        0.002674  \n",
       "25%        0.003719  \n",
       "50%        0.004292  \n",
       "75%        0.004832  \n",
       "max        0.006476  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation\n",
    "\n",
    "1. Convert datetime into hour of day (numeric)\n",
    "2. Label Encode our Class \n",
    "3. Transform dictionaries into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateEncode(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom transformers extend sklearn.base.BaseEstimator and TransformerMixin \n",
    "    to add helper methods like fit_transform(). It is up to you to add the \n",
    "    following methods:\n",
    "    \n",
    "        1. fit(X, y=None)\n",
    "        2. transform(X)\n",
    "    \n",
    "    This transfomer encodes the datetime into hour of day and day of week features. \n",
    "    \"\"\"\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Expects X to be a list of dictionaries. \n",
    "        \n",
    "        Loops through all dictionaries to find all unique dictionary keys \n",
    "        whose values are datetimes, in order to \"learn\" what fields to \n",
    "        encode date time as. \n",
    "        \n",
    "        For this data, this will only be the \"datetime\" field, but this \n",
    "        method is added here as an example of fitting to data. \n",
    "        \"\"\"\n",
    "        # NOTE: properties suffixed with an underscore are internal \n",
    "        # attributes that are learned during fit \n",
    "        self.date_columns_ = set([\n",
    "            key \n",
    "            for Xi in X \n",
    "            for key, val in Xi.items()\n",
    "            if isinstance(val, datetime)\n",
    "        ])\n",
    "        \n",
    "        # NOTE: fit must always return self \n",
    "        return self \n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Expects X to be a list of dictionaries. \n",
    "        \n",
    "        Pops (deletes) the datetime fields discovered during fit \n",
    "        and replaces it with the following features:\n",
    "        \n",
    "            1. field_hour : the hour of day \n",
    "            2. field_dow : the day of the week \n",
    "        \n",
    "        Returns a list of dictionaries\n",
    "        \"\"\"\n",
    "        Xprime = []\n",
    "        for Xi in X:\n",
    "            for col in self.date_columns_:\n",
    "                dt = Xi.pop(col)\n",
    "                Xi[col + \"_hour\"] = dt.hour \n",
    "                Xi[col + \"_dow\"] = dt.weekday()\n",
    "            Xprime.append(Xi)\n",
    "        return Xprime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Raw Data - data is a list of tuples [(features, target)]\n",
    "# Extract the features into X and the target into y \n",
    "data = list(load_raw())\n",
    "X = [row[0] for row in data]\n",
    "y = [row[1] for row in data]\n",
    "\n",
    "# Create feature extraction pipeline \n",
    "features = Pipeline([\n",
    "    ('date_encode', DateEncode()),\n",
    "    ('vec', DictVectorizer()), \n",
    "])\n",
    "\n",
    "# Fit transfrom the features, which should now be a 2D array \n",
    "Xp = features.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encode the target, which should now be a 1D vector \n",
    "label_encoder = LabelEncoder()\n",
    "yp = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamin/.pyenv/versions/3.6.2/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['occupied', 'unoccupied', 'unoccupied', 'occupied', 'occupied'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of getting the class name back from the encoder \n",
    "label_encoder.inverse_transform([0,1,1,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape is (20560, 7) y shape is (20560,)\n"
     ]
    }
   ],
   "source": [
    "# Always check the shape of X and y makes sense \n",
    "print(\"X shape is {} y shape is {}\".format(\n",
    "    Xp.shape, yp.shape\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ClassBalance, ConfusionMatrix, ClassificationReport\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_evaluate_model(model, X=Xp.todense(), y=yp, encoder=label_encoder):\n",
    "    X_train, X_test, y_train, y_test = tts(X, y, train_size=0.80, shuffle=True)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_hat = model.predict(X_test)\n",
    "    print(\"f1: {}\".format(f1_score(y_test, y_hat, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamin/.pyenv/versions/3.6.2/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.9908079074134394\n"
     ]
    }
   ],
   "source": [
    "# Simple Evaluation\n",
    "clf = GradientBoostingClassifier()\n",
    "simple_evaluate_model(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9332792814271315"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Complete Evaluation \n",
    "model = Pipeline([\n",
    "    ('date_encode', DateEncode()),\n",
    "    ('vec', DictVectorizer()), \n",
    "    ('clf', GradientBoostingClassifier())\n",
    "])\n",
    "\n",
    "cross_val_score(model, X, y, cv=12, scoring='f1_macro').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.9876606195595065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamin/.pyenv/versions/3.6.2/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Simpler Model\n",
    "# Simple Evaluation \n",
    "clf = GradientBoostingClassifier(n_estimators=5)\n",
    "simple_evaluate_model(clf, Xp.todense(), yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9811118919383479"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, Xp.todense(), yp, cv=12, scoring='f1_macro').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.9903461571949985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamin/.pyenv/versions/3.6.2/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "simple_evaluate_model(clf, Xp.todense(), yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9842681993775103"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, Xp.todense(), yp, cv=12, scoring='f1_macro').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.9684081908555003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamin/.pyenv/versions/3.6.2/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "simple_evaluate_model(clf, Xp.todense(), yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9262619405255568"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, Xp.todense(), yp, cv=12, scoring='f1_macro').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def internal_params(estimator):\n",
    "    for attr in dir(estimator):\n",
    "        if attr.endswith(\"_\") and not attr.startswith(\"_\"):\n",
    "            yield attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path=None):\n",
    "    if path is None:\n",
    "        path = model.__class__.__name__ + \".pkl\"\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class_count_', 'class_prior_', 'classes_', 'sigma_', 'theta_']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(internal_params(clf))\n",
    "#save_model(clf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
